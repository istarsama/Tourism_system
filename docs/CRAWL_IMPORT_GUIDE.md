# ğŸ•·ï¸ çˆ¬è™«æ•°æ®å¯¼å…¥æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ æŠŠä»å°çº¢ä¹¦çˆ¬å–çš„æ•°æ®æ•´åˆå¹¶å¯¼å…¥åˆ°æ•°æ®åº“ä¸­ã€‚

---

## ğŸ“‹ å‡†å¤‡å·¥ä½œ

### 1. é…ç½® Cookieï¼ˆå¿…é¡»ï¼‰

åœ¨æµè§ˆå™¨ä¸­è·å–å°çº¢ä¹¦çš„ Cookieï¼š

1. æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® [xiaohongshu.com](https://www.xiaohongshu.com)
2. **ç™»å½•ä½ çš„è´¦å·**
3. æŒ‰ `F12` æ‰“å¼€å¼€å‘è€…å·¥å…·
4. åˆ‡æ¢åˆ° **Networkï¼ˆç½‘ç»œï¼‰** æ ‡ç­¾
5. åˆ·æ–°é¡µé¢ï¼ˆF5ï¼‰
6. ç‚¹å‡»ä»»æ„ä¸€ä¸ªè¯·æ±‚ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªï¼‰
7. åœ¨å³ä¾§æ‰¾åˆ° **Request Headers** â†’ **Cookie**
8. å¤åˆ¶æ•´ä¸ª Cookie å­—ç¬¦ä¸²ï¼ˆå¾ˆé•¿çš„ä¸€ä¸²ï¼‰
9. åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```env
XHS_COOKIE=ä½ å¤åˆ¶çš„å®Œæ•´Cookieå†…å®¹
```

### 2. æ£€æŸ¥ä¾èµ–

ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åŒ…ï¼š

```bash
uv sync
```

### 3. ç¡®è®¤æ•°æ®åº“è¿æ¥

```bash
uv run view_database.py
```

å¦‚æœèƒ½çœ‹åˆ°æ•°æ®ç»Ÿè®¡ï¼Œè¯´æ˜æ•°æ®åº“è¿æ¥æ­£å¸¸ã€‚

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1ï¼šäº¤äº’å¼å¯¼å…¥ï¼ˆæ¨èï¼‰

```bash
uv run import_crawled_data.py
```

æŒ‰ç…§æç¤ºæ“ä½œï¼š
1. è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆå¦‚ "åŒ—é‚®é£Ÿå ‚"ï¼‰
2. ç³»ç»Ÿä¼šè‡ªåŠ¨åŒ¹é…å¯¹åº”çš„æ™¯ç‚¹
3. é€‰æ‹©çˆ¬å–æ•°é‡ï¼ˆå»ºè®®5-10æ¡ï¼‰
4. é¢„è§ˆæ•°æ®åç¡®è®¤å¯¼å…¥

**ç¤ºä¾‹è¿è¡Œï¼š**

```
ğŸ•·ï¸  å°çº¢ä¹¦æ•°æ®çˆ¬å–ä¸å¯¼å…¥å·¥å…·
================================================
âœ… Cookie é…ç½®å·²æ£€æµ‹åˆ°
âœ… å·²åŠ è½½ 44 ä¸ªæ™¯ç‚¹æ•°æ®

ğŸ“Œ è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆå¦‚ 'åŒ—é‚®é£Ÿå ‚' 'å›¾ä¹¦é¦†è‡ªä¹ 'ï¼‰: å­¦ä¸€é£Ÿå ‚
   ğŸ¯ æ™ºèƒ½åŒ¹é…åˆ°æ™¯ç‚¹: å­¦ç”Ÿé£Ÿå ‚ (ç›¸ä¼¼åº¦: 85%)
   æ˜¯å¦ç»‘å®šåˆ°è¯¥æ™¯ç‚¹ï¼Ÿ(Y/n): y
   âœ… å·²ç»‘å®šåˆ°: å­¦ç”Ÿé£Ÿå ‚ (ID: 44)

ğŸ“Š çˆ¬å–æ•°é‡ï¼ˆé»˜è®¤5æ¡ï¼Œæœ€å¤š20æ¡ï¼‰: 5

ğŸš€ å¼€å§‹ä»å°çº¢ä¹¦çˆ¬å–å…³é”®è¯ã€å­¦ä¸€é£Ÿå ‚ã€‘çš„ç¬”è®°...
âœ… æˆåŠŸçˆ¬å– 5 æ¡ç¬”è®°

ğŸ“„ æ•°æ®é¢„è§ˆ:
1. å­¦ä¸€é£Ÿå ‚æ¢åº— | è¿™å®¶çª—å£å·¨å¥½åƒï¼
   ä½œè€…: ç¾é£Ÿåšä¸»å°ç‹ | ç‚¹èµ: 1234
2. åŒ—é‚®å¿…åƒæ¦œ | å­¦ä¸€é£Ÿå ‚TOP5æ¨è
   ä½œè€…: æ ¡å›­åƒè´§ | ç‚¹èµ: 856
...

æ˜¯å¦å¯¼å…¥åˆ°æ•°æ®åº“ï¼Ÿ(Y/n): y

ğŸ“ å¼€å§‹å†™å…¥æ•°æ®åº“...
   âœ… 1. æˆåŠŸå¯¼å…¥: [æ¬è¿] å­¦ä¸€é£Ÿå ‚æ¢åº— | è¿™å®¶çª—å£...
   âœ… 2. æˆåŠŸå¯¼å…¥: [æ¬è¿] åŒ—é‚®å¿…åƒæ¦œ | å­¦ä¸€é£Ÿå ‚...
   ...

âœ… å¯¼å…¥å®Œæˆ: æˆåŠŸ 5 æ¡, å¤±è´¥ 0 æ¡
```

---

### æ–¹å¼2ï¼šæ‰¹é‡å¯¼å…¥

ä¸€æ¬¡æ€§å¯¼å…¥å¤šä¸ªå…³é”®è¯ï¼š

```bash
uv run import_crawled_data.py "å­¦ä¸€é£Ÿå ‚" "å›¾ä¹¦é¦†è‡ªä¹ " "è¿åŠ¨åœº"
```

ç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
- ä¸ºæ¯ä¸ªå…³é”®è¯çˆ¬å–5æ¡æ•°æ®
- æ™ºèƒ½åŒ¹é…å¯¹åº”çš„æ™¯ç‚¹
- è‡ªåŠ¨å¯¼å…¥åˆ°æ•°æ®åº“

---

### æ–¹å¼3ï¼šä½¿ç”¨æ—§ç‰ˆè„šæœ¬

å¦‚æœä½ æ›´ç†Ÿæ‚‰åŸæ¥çš„ `crawl_import.py`ï¼š

```bash
uv run crawl_import.py
```

---

## ğŸ“Š æ•°æ®ç»“æ„è¯´æ˜

### çˆ¬å–çš„åŸå§‹æ•°æ®

```json
{
  "note_id": "xhs_123456",
  "title": "åŒ—é‚®é£Ÿå ‚æ¢åº—",
  "desc": "ä»Šå¤©å»å­¦ä¸€é£Ÿå ‚åƒäº†...",
  "user": {
    "nickname": "ç¾é£Ÿåšä¸»",
    "id": "user_123"
  },
  "likes": 1234,
  "images": ["http://image1.jpg", "http://image2.jpg"]
}
```

### å¯¼å…¥åˆ°æ•°æ®åº“åçš„æ ¼å¼

| å­—æ®µ | å€¼ | è¯´æ˜ |
|------|-----|------|
| `title` | `[æ¬è¿] åŒ—é‚®é£Ÿå ‚æ¢åº—` | æ ‡é¢˜å‰åŠ  `[æ¬è¿]` æ ‡è®° |
| `content` | åŒ…å«åŸä½œè€…ã€ç‚¹èµæ•°ã€æ­£æ–‡ | ç»„åˆå†…å®¹ |
| `user_id` | `5 (spider_bot)` | å›ºå®šä½¿ç”¨çˆ¬è™«è´¦å· |
| `spot_id` | `44 (å­¦ç”Ÿé£Ÿå ‚)` | æ™ºèƒ½åŒ¹é…æˆ–æ‰‹åŠ¨æŒ‡å®š |
| `view_count` | `1234` | ä½¿ç”¨åŸç¬”è®°çš„ç‚¹èµæ•° |
| `media_json` | `["url1", "url2"]` | JSON æ ¼å¼ä¿å­˜å›¾ç‰‡é“¾æ¥ |
| `score` | `4.0` | é»˜è®¤è¯„åˆ† |

---

## ğŸ¯ æ™ºèƒ½æ™¯ç‚¹åŒ¹é…

ç³»ç»Ÿä¼šæ ¹æ®å…³é”®è¯è‡ªåŠ¨åŒ¹é…æ™¯ç‚¹ï¼š

| å…³é”®è¯ | åŒ¹é…æ™¯ç‚¹ | ç›¸ä¼¼åº¦ |
|--------|----------|--------|
| "å­¦ä¸€é£Ÿå ‚" | å­¦ç”Ÿé£Ÿå ‚ (ID:44) | 85% |
| "å›¾ä¹¦é¦†è‡ªä¹ " | å›¾ä¹¦é¦† (ID:57) | 90% |
| "åŒ—é‚®æ˜Ÿå¡”" | åŒ—é‚®æ˜Ÿå¡” (ID:54) | 100% |
| "è¿åŠ¨åœºè·‘æ­¥" | è¿åŠ¨åœº (ID:46) | 80% |

**åŒ¹é…è§„åˆ™ï¼š**
1. ç²¾ç¡®åŒ¹é…ï¼šå…³é”®è¯åŒ…å«æ™¯ç‚¹åæˆ–åä¹‹
2. æ¨¡ç³ŠåŒ¹é…ï¼šä½¿ç”¨ Levenshtein è·ç¦»ç®—æ³•
3. ç›¸ä¼¼åº¦ > 60% æ‰ç®—åŒ¹é…æˆåŠŸ

---

## ğŸ” æŸ¥çœ‹å¯¼å…¥çš„æ•°æ®

### 1. æŸ¥çœ‹æ‰€æœ‰æ—¥è®°

```bash
uv run view_database.py
```

### 2. æŸ¥çœ‹çˆ¬è™«è´¦å·å‘å¸ƒçš„æ—¥è®°

åœ¨ MySQL å®¢æˆ·ç«¯ä¸­ï¼š

```sql
-- æŸ¥çœ‹çˆ¬è™«å¯¼å…¥çš„æ‰€æœ‰æ—¥è®°
SELECT id, title, spot_id, view_count 
FROM diary 
WHERE user_id = 5 
ORDER BY created_at DESC;

-- æŸ¥çœ‹æŸä¸ªæ™¯ç‚¹çš„æ‰€æœ‰æ—¥è®°
SELECT title, content 
FROM diary 
WHERE spot_id = 44;
```

### 3. é€šè¿‡ API æŸ¥çœ‹

å¯åŠ¨åç«¯ï¼š

```bash
uv run uvicorn src.api:app --reload
```

è®¿é—®ï¼š
- æ‰€æœ‰æ—¥è®°ï¼š`http://localhost:8000/diaries/spot/44`
- æœç´¢ï¼š`http://localhost:8000/diaries/search?q=é£Ÿå ‚`

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: Cookie è¿‡æœŸäº†æ€ä¹ˆåŠï¼Ÿ

**ç—‡çŠ¶ï¼š** 
- æç¤º "ç™»å½•å¤±æ•ˆ"
- çˆ¬å–åˆ°çš„æ•°æ®ä¸ºç©º
- è¿”å› 401 é”™è¯¯

**è§£å†³ï¼š**
é‡æ–°æŒ‰ç…§ [å‡†å¤‡å·¥ä½œ](#å‡†å¤‡å·¥ä½œ) è·å–æ–°çš„ Cookieï¼Œæ›´æ–° `.env` æ–‡ä»¶ã€‚

Cookie é€šå¸¸æœ‰æ•ˆæœŸä¸º **7-30å¤©**ï¼Œå»ºè®®å®šæœŸæ›´æ–°ã€‚

---

### Q2: ä¸ºä»€ä¹ˆæ²¡æœ‰çˆ¬åˆ°æ•°æ®ï¼Ÿ

å¯èƒ½åŸå› ï¼š
1. **Cookie æœªé…ç½®æˆ–è¿‡æœŸ** â†’ æ£€æŸ¥ `.env` æ–‡ä»¶
2. **å…³é”®è¯å¤ªå†·é—¨** â†’ æ¢ä¸ªçƒ­é—¨å…³é”®è¯è¯•è¯•
3. **ç½‘ç»œè¿æ¥é—®é¢˜** â†’ æ£€æŸ¥èƒ½å¦è®¿é—® xiaohongshu.com
4. **å°çº¢ä¹¦æ¥å£å˜åŠ¨** â†’ ç­‰å¾…çˆ¬è™«æ¨¡å—æ›´æ–°

---

### Q3: å¦‚ä½•é¿å…é‡å¤å¯¼å…¥ï¼Ÿ

ç³»ç»Ÿä¼šè‡ªåŠ¨å»é‡ï¼Œé€šè¿‡ **æ ‡é¢˜** åˆ¤æ–­ï¼š
- å¦‚æœæ ‡é¢˜å®Œå…¨ç›¸åŒï¼Œä¼šè·³è¿‡
- å»ºè®®æ¯æ¬¡çˆ¬å–ä¸åŒçš„å…³é”®è¯

---

### Q4: å¯¼å…¥çš„å›¾ç‰‡èƒ½æ­£å¸¸æ˜¾ç¤ºå—ï¼Ÿ

- çˆ¬è™«ä¿å­˜çš„æ˜¯ **å°çº¢ä¹¦çš„å›¾ç‰‡ URL**
- è¿™äº› URL å¯èƒ½æœ‰é˜²ç›—é“¾æˆ–è¿‡æœŸ
- å¦‚éœ€é•¿æœŸä¿å­˜ï¼Œå»ºè®®ï¼š
  1. ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ° `downloads/media/`
  2. ä¿®æ”¹ `media_json` ä¸ºæœ¬åœ°è·¯å¾„
  3. é€šè¿‡ `/upload` æ¥å£ä¸Šä¼ åˆ°æœåŠ¡å™¨

---

### Q5: èƒ½çˆ¬å–ç”¨æˆ·çš„æ‰€æœ‰ç¬”è®°å—ï¼Ÿ

å¯ä»¥ï¼Œä½†éœ€è¦ä¿®æ”¹ä»£ç ï¼š

```python
# åœ¨ import_crawled_data.py ä¸­æ·»åŠ 
def crawl_user_notes(user_url):
    crawler = XHSCrawler()
    # è°ƒç”¨ spider_user_all_note æ–¹æ³•
    ...
```

---

## ğŸ¨ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ•°æ®æ¸…æ´—

ä¿®æ”¹ [import_crawled_data.py](import_crawled_data.py) ä¸­çš„ `clean_and_format_note` å‡½æ•°ï¼š

```python
def clean_and_format_note(note: dict) -> dict:
    # è‡ªå®šä¹‰æ¸…æ´—é€»è¾‘
    title = note.get('title', '').strip()
    
    # è¿‡æ»¤å¹¿å‘Šè¯
    if any(word in title for word in ['å¹¿å‘Š', 'æ¨å¹¿']):
        return None
    
    # é™åˆ¶å†…å®¹é•¿åº¦
    content = note.get('desc', '')[:1000]
    
    return {
        'title': title,
        'content': content,
        # ...
    }
```

---

### å®šæ—¶è‡ªåŠ¨çˆ¬å–

ä½¿ç”¨ **cron**ï¼ˆLinux/Macï¼‰æˆ– **ä»»åŠ¡è®¡åˆ’ç¨‹åº**ï¼ˆWindowsï¼‰ï¼š

```bash
# æ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨çˆ¬å–
0 2 * * * cd /path/to/project && uv run import_crawled_data.py "å…³é”®è¯"
```

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| [import_crawled_data.py](import_crawled_data.py) | ğŸ†• æ–°ç‰ˆæ•°æ®å¯¼å…¥å·¥å…·ï¼ˆæ¨èï¼‰ |
| [crawl_import.py](crawl_import.py) | æ—§ç‰ˆå¯¼å…¥è„šæœ¬ |
| [src/crawler.py](src/crawler.py) | çˆ¬è™«æ ¸å¿ƒé€»è¾‘ |
| [src/tools/Spider_XHS/](src/tools/Spider_XHS/) | å°çº¢ä¹¦çˆ¬è™«æ¨¡å— |
| [view_database.py](view_database.py) | æ•°æ®åº“æŸ¥çœ‹å·¥å…· |

---

## ğŸ‰ å®Œæ•´æµç¨‹ç¤ºä¾‹

```bash
# 1. æ£€æŸ¥æ•°æ®åº“
uv run view_database.py

# 2. å¯¼å…¥æ•°æ®
uv run import_crawled_data.py
# è¾“å…¥: å­¦ä¸€é£Ÿå ‚
# çˆ¬å–: 5 æ¡
# ç¡®è®¤: y

# 3. å†æ¬¡æŸ¥çœ‹æ•°æ®åº“
uv run view_database.py
# åº”è¯¥èƒ½çœ‹åˆ°æ–°å¢çš„ 5 æ¡æ—¥è®°

# 4. å¯åŠ¨åç«¯æµ‹è¯•
uv run uvicorn src.api:app --reload

# 5. æµ‹è¯• AI RAG
# åœ¨å‰ç«¯é—®: "å­¦ä¸€é£Ÿå ‚å¤§å®¶éƒ½æ¨èä»€ä¹ˆï¼Ÿ"
# AI ä¼šä»åˆšå¯¼å…¥çš„æ•°æ®ä¸­æ£€ç´¢å›ç­”
```

---

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡ä½¿ç”¨å»ºè®®çˆ¬å– 3-5 æ¡æµ‹è¯•**ï¼Œç¡®è®¤æµç¨‹æ­£å¸¸åå†æ‰¹é‡å¯¼å…¥
2. **å…³é”®è¯é€‰æ‹©æŠ€å·§**ï¼š
   - âœ… å¥½çš„ï¼š`å­¦ä¸€é£Ÿå ‚ç¾é£Ÿ` `å›¾ä¹¦é¦†è‡ªä¹ æ¨è` `åŒ—é‚®æ˜Ÿå¡”æ‰“å¡`
   - âŒ å·®çš„ï¼š`å¥½åƒ` `æ™¯ç‚¹` `æ¨è`ï¼ˆå¤ªå®½æ³›ï¼‰
3. **å¯¼å…¥åè®°å¾—æµ‹è¯• RAG åŠŸèƒ½**ï¼Œç¡®ä¿ AI èƒ½æ£€ç´¢åˆ°æ–°æ•°æ®
4. **å®šæœŸæ¸…ç†é‡å¤æ•°æ®**ï¼Œä¿æŒæ•°æ®åº“æ•´æ´

---

éœ€è¦å¸®åŠ©ï¼ŸæŸ¥çœ‹ [README.md](README.md) æˆ–æäº¤ Issueã€‚
