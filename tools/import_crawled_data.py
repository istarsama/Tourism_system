"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ•·ï¸ å°çº¢ä¹¦çˆ¬è™«æ•°æ®æ•´åˆå¯¼å…¥å·¥å…· (Crawler Data Integration Tool)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ã€åŠŸèƒ½è¯´æ˜ã€‘
ä»å°çº¢ä¹¦çˆ¬å–ç¬”è®°æ•°æ®ï¼Œç»è¿‡æ™ºèƒ½å¤„ç†åå¯¼å…¥åˆ°æ—…æ¸¸ç³»ç»Ÿæ•°æ®åº“ã€‚

ã€æ ¸å¿ƒåŠŸèƒ½ã€‘
1. ğŸ” æ•°æ®çˆ¬å– - ä»å°çº¢ä¹¦APIçˆ¬å–ç¬”è®°å†…å®¹
2. ğŸ§¹ æ•°æ®æ¸…æ´— - æ ¼å¼åŒ–å†…å®¹ï¼Œæ§åˆ¶é•¿åº¦ï¼Œæå–å…³é”®ä¿¡æ¯
3. ğŸ¯ æ™ºèƒ½åŒ¹é… - æ ¹æ®å…³é”®è¯è‡ªåŠ¨åŒ¹é…æ™¯ç‚¹IDï¼ˆæ¨¡ç³ŠåŒ¹é…ç®—æ³•ï¼‰
4. ğŸ—‘ï¸ å»é‡å¤„ç† - é¿å…é‡å¤å¯¼å…¥ç›¸åŒæ•°æ®
5. ğŸ’¾ æ•°æ®åº“å­˜å‚¨ - ä¿å­˜ä¸ºç³»ç»Ÿæ—¥è®°ï¼Œä¾›AI RAGæ£€ç´¢

ã€ä½¿ç”¨æ–¹å¼ã€‘
1. äº¤äº’å¼: uv run tools/import_crawled_data.py
2. æ‰¹é‡æ¨¡å¼: uv run tools/import_crawled_data.py "å…³é”®è¯1" "å…³é”®è¯2"
3. èœå•å…¥å£: uv run python run_tests.py â†’ è¾“å…¥ c

ã€æŠ€æœ¯æ ˆã€‘
- çˆ¬è™«ï¼šSpider_XHSæ¨¡å—ï¼ˆå°çº¢ä¹¦APIå°è£…ï¼‰
- åŒ¹é…ï¼šthefuzzæ¨¡ç³ŠåŒ¹é…ç®—æ³•ï¼ˆLevenshteinè·ç¦»ï¼‰
- æ•°æ®åº“ï¼šSQLModel + MySQL
- è®¤è¯ï¼šCookieæœºåˆ¶ï¼ˆä».envè¯»å–ï¼‰

ã€æ•°æ®æµã€‘
å°çº¢ä¹¦ â†’ çˆ¬è™«API â†’ æ•°æ®æ¸…æ´— â†’ æ™¯ç‚¹åŒ¹é… â†’ å»é‡æ£€æŸ¥ â†’ MySQL â†’ AI RAG

ã€æ³¨æ„äº‹é¡¹ã€‘
1. éœ€è¦åœ¨.envä¸­é…ç½® XHS_COOKIE
2. Cookieæœ‰æ•ˆæœŸ7-30å¤©ï¼Œè¿‡æœŸéœ€é‡æ–°è·å–
3. æ¨èå…³é”®è¯ï¼šåŒ—é‚®é£Ÿå ‚ã€å›¾ä¹¦é¦†è‡ªä¹ ã€åŒ—é‚®æ ¡å›­
4. æ‰€æœ‰çˆ¬è™«æ•°æ®ç»Ÿä¸€ä½¿ç”¨ spider_bot è´¦å·ï¼ˆID: 5ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
import sys
import os
import json
from datetime import datetime
from dotenv import load_dotenv
from sqlmodel import Session, select

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ“¦ æ¨¡å—å¯¼å…¥å’Œè·¯å¾„é…ç½®
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# 1. ç¯å¢ƒå‡†å¤‡ - æ·»åŠ  src ç›®å½•åˆ° Python è·¯å¾„
# åŸå› ï¼šéœ€è¦å¯¼å…¥ crawler, database, models ç­‰è‡ªå®šä¹‰æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, "..")
src_path = os.path.join(project_root, "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# 2. å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from crawler import XHSCrawler          # å°çº¢ä¹¦çˆ¬è™«å°è£…ç±»
from database import engine             # æ•°æ®åº“å¼•æ“
from models import User, Diary          # æ•°æ®æ¨¡å‹
from auth import get_password_hash      # å¯†ç å“ˆå¸Œå·¥å…·

# 3. å¯¼å…¥å·¥å…·å‡½æ•°
from utils import load_graph_from_json, get_data_path  # æ™¯ç‚¹æ•°æ®åŠ è½½

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ¤– çˆ¬è™«è´¦å·ç®¡ç†
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_or_create_spider_user(session: Session):
    """
    è·å–æˆ–åˆ›å»ºçˆ¬è™«ä¸“ç”¨è´¦å· (spider_bot)
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    ä¸ºæ‰€æœ‰çˆ¬è™«å¯¼å…¥çš„æ•°æ®åˆ›å»ºä¸€ä¸ªç»Ÿä¸€çš„è™šæ‹Ÿç”¨æˆ·è´¦å·ï¼Œä¾¿äºç®¡ç†å’Œè¿½è¸ªã€‚
    
    ã€è´¦å·ä¿¡æ¯ã€‘
    - ç”¨æˆ·å: spider_bot
    - å¯†ç : spider123 (å·²å“ˆå¸Œ)
    - ç”¨é€”: æ ‡è¯†æ‰€æœ‰ä»å°çº¢ä¹¦çˆ¬å–çš„æ—¥è®°
    - å›ºå®šID: 5 (è‡ªåŠ¨ç”Ÿæˆ)
    
    ã€è®¾è®¡åŸå› ã€‘
    1. åŒºåˆ†çœŸå®ç”¨æˆ·å’Œçˆ¬è™«æ•°æ®
    2. ä¾¿äºç»Ÿè®¡å’Œç®¡ç†çˆ¬è™«å†…å®¹
    3. é˜²æ­¢æ··æ·†æ•°æ®æ¥æº
    4. æ”¯æŒåç»­çš„æ•°æ®æ¸…ç†å’Œæ›´æ–°
    
    å‚æ•°:
        session: æ•°æ®åº“ä¼šè¯
    
    è¿”å›:
        User: çˆ¬è™«è´¦å·å¯¹è±¡
    """
    # æŸ¥è¯¢æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨ spider_bot è´¦å·
    user = session.exec(select(User).where(User.username == "spider_bot")).first()
    
    if not user:
        # ä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°è´¦å·
        print("ğŸ¤– åˆ›å»ºçˆ¬è™«æ¬è¿å·¥è´¦å· 'spider_bot'...")
        user = User(
            username="spider_bot", 
            password_hash=get_password_hash("spider123")
        )
        session.add(user)
        session.commit()
        session.refresh(user)
    
    return user

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ—ºï¸ æ™¯ç‚¹æ•°æ®ç®¡ç†
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def load_spots():
    """
    ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰æ™¯ç‚¹æ•°æ®
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    è¯»å– data/campus_map.json ä¸­çš„æ™¯ç‚¹ä¿¡æ¯ï¼Œæ„å»ºæ™¯ç‚¹å­—å…¸ä¾›åŒ¹é…ä½¿ç”¨ã€‚
    
    ã€æ•°æ®ç»“æ„ã€‘
    è¿”å›æ ¼å¼: {spot_id: Spotå¯¹è±¡}
    ä¾‹å¦‚: {
        44: Spot(id=44, name="å­¦ç”Ÿé£Ÿå ‚", type="spot"),
        57: Spot(id=57, name="å›¾ä¹¦é¦†", type="spot"),
        ...
    }
    
    ã€è¿‡æ»¤è§„åˆ™ã€‘
    åªåŠ è½½ type="spot" çš„æ™¯ç‚¹ï¼Œæ’é™¤é“è·¯ã€å»ºç­‘ç­‰å…¶ä»–ç±»å‹èŠ‚ç‚¹ã€‚
    
    è¿”å›:
        dict: {æ™¯ç‚¹ID: æ™¯ç‚¹å¯¹è±¡} çš„å­—å…¸
    """
    try:
        # ä» JSON æ–‡ä»¶åŠ è½½æ ¡å›­åœ°å›¾æ•°æ®
        graph = load_graph_from_json(get_data_path())
        
        # ç­›é€‰å‡ºæ‰€æœ‰æ™¯ç‚¹ï¼ˆæ’é™¤é“è·¯ç­‰èŠ‚ç‚¹ï¼‰
        spots = {spot.id: spot for spot in graph.spots.values() if spot.type == "spot"}
        
        return spots
    except Exception as e:
        print(f"âš ï¸ åŠ è½½æ™¯ç‚¹æ•°æ®å¤±è´¥: {e}")
        return {}

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ¯ æ™ºèƒ½æ™¯ç‚¹åŒ¹é…ç®—æ³•
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def find_spot_by_keyword(keyword: str, spots: dict):
    """
    æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯æ™ºèƒ½åŒ¹é…å¯¹åº”æ™¯ç‚¹
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    ä½¿ç”¨ä¸¤çº§åŒ¹é…ç­–ç•¥ï¼Œä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå…¶æ¬¡æ¨¡ç³ŠåŒ¹é…ã€‚
    
    ã€åŒ¹é…ç­–ç•¥ã€‘
    1. ç²¾ç¡®åŒ¹é… - å…³é”®è¯åŒ…å«æ™¯ç‚¹åæˆ–æ™¯ç‚¹ååŒ…å«å…³é”®è¯
       ä¾‹å¦‚: "åŒ—é‚®é£Ÿå ‚" åŒ…å« "é£Ÿå ‚" â†’ åŒ¹é…æˆåŠŸ
    
    2. æ¨¡ç³ŠåŒ¹é… - ä½¿ç”¨ Levenshtein è·ç¦»ç®—æ³•ï¼ˆç¼–è¾‘è·ç¦»ï¼‰
       ç®—æ³•: thefuzz.fuzz.partial_ratio()
       é˜ˆå€¼: ç›¸ä¼¼åº¦ > 60% è®¤ä¸ºåŒ¹é…æˆåŠŸ
       
    ã€åŒ¹é…ç¤ºä¾‹ã€‘
    | å…³é”®è¯ | åŒ¹é…æ™¯ç‚¹ | ç›¸ä¼¼åº¦ | ç­–ç•¥ |
    |--------|----------|--------|------|
    | "åŒ—é‚®é£Ÿå ‚" | å­¦ç”Ÿé£Ÿå ‚ | 85% | æ¨¡ç³Š |
    | "å›¾ä¹¦é¦†è‡ªä¹ " | å›¾ä¹¦é¦† | 90% | æ¨¡ç³Š |
    | "é£Ÿå ‚" | å­¦ç”Ÿé£Ÿå ‚ | 100% | ç²¾ç¡® |
    | "æ˜Ÿå¡”" | åŒ—é‚®æ˜Ÿå¡” | 100% | ç²¾ç¡® |
    
    ã€ç®—æ³•åŸç†ã€‘
    Levenshtein Distanceï¼ˆè±æ–‡æ–¯å¦è·ç¦»ï¼‰:
    è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²ä¹‹é—´éœ€è¦å¤šå°‘æ¬¡æ’å…¥ã€åˆ é™¤ã€æ›¿æ¢æ“ä½œæ‰èƒ½ç›¸äº’è½¬æ¢ã€‚
    è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ã€‚
    
    å‚æ•°:
        keyword: ç”¨æˆ·è¾“å…¥çš„æœç´¢å…³é”®è¯
        spots: æ™¯ç‚¹å­—å…¸ {id: Spotå¯¹è±¡}
    
    è¿”å›:
        Spot: åŒ¹é…åˆ°çš„æ™¯ç‚¹å¯¹è±¡ï¼ŒæœªåŒ¹é…è¿”å› None
    """
    keyword_lower = keyword.lower()
    
    # â”â”â” ç¬¬ä¸€è½®: ç²¾ç¡®åŒ¹é… â”â”â”
    # æ£€æŸ¥å…³é”®è¯å’Œæ™¯ç‚¹åæ˜¯å¦äº’ç›¸åŒ…å«
    for spot_id, spot in spots.items():
        if keyword in spot.name or spot.name in keyword:
            return spot
    
    # â”â”â” ç¬¬äºŒè½®: æ¨¡ç³ŠåŒ¹é… â”â”â”
    # ä½¿ç”¨ thefuzz åº“è®¡ç®—ç›¸ä¼¼åº¦
    from thefuzz import fuzz
    
    best_match = None    # æœ€ä½³åŒ¹é…çš„æ™¯ç‚¹
    best_score = 0       # æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°
    
    # éå†æ‰€æœ‰æ™¯ç‚¹ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
    for spot_id, spot in spots.items():
        # partial_ratio: éƒ¨åˆ†åŒ¹é…ç®—æ³•ï¼Œå¤„ç†é•¿åº¦ä¸ç­‰çš„å­—ç¬¦ä¸²
        score = fuzz.partial_ratio(keyword, spot.name)
        if score > best_score:
            best_score = score
            best_match = spot
    
    # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°åŒ¹é…é˜ˆå€¼ï¼ˆ60%ï¼‰
    if best_score > 60:
        print(f"   ğŸ¯ æ™ºèƒ½åŒ¹é…åˆ°æ™¯ç‚¹: {best_match.name} (ç›¸ä¼¼åº¦: {best_score}%)")
        return best_match
    
    # æœªæ‰¾åˆ°åŒ¹é…
    return None

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ§¹ æ•°æ®æ¸…æ´—ä¸æ ¼å¼åŒ–
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def clean_and_format_note(note: dict) -> dict:
    """
    æ¸…æ´—å’Œæ ¼å¼åŒ–ä»å°çº¢ä¹¦çˆ¬å–çš„ç¬”è®°æ•°æ®
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    å¯¹åŸå§‹JSONæ•°æ®è¿›è¡Œè§„èŒƒåŒ–å¤„ç†ï¼Œç¡®ä¿ç¬¦åˆæ•°æ®åº“å­—æ®µè¦æ±‚ã€‚
    
    ã€å¤„ç†æµç¨‹ã€‘
    1. æå–æ ¸å¿ƒå­—æ®µï¼ˆæ ‡é¢˜ã€å†…å®¹ã€ä½œè€…ï¼‰
    2. é•¿åº¦æ§åˆ¶ï¼ˆé˜²æ­¢è¶…å‡ºæ•°æ®åº“é™åˆ¶ï¼‰
    3. æˆªæ–­è¶…é•¿éƒ¨åˆ†å¹¶æ·»åŠ çœç•¥å·
    4. è¿”å›æ ‡å‡†åŒ–çš„å­—å…¸æ•°æ®
    
    ã€é•¿åº¦é™åˆ¶ã€‘
    - æ ‡é¢˜: 400å­—ç¬¦ï¼ˆæ•°æ®åº“VARCHAR(500)ï¼Œç•™100å­—ä½™é‡ï¼‰
    - å†…å®¹: 5000å­—ç¬¦ï¼ˆæ•°æ®åº“TEXTç±»å‹æ”¯æŒ65Kï¼Œä½†é¿å…è¿‡é•¿ï¼‰
    - ä½œè€…: 100å­—ç¬¦
    - å›¾ç‰‡: æœ€å¤š9å¼ 
    
    ã€æ•°æ®åº“å‡çº§èƒŒæ™¯ã€‘
    - åŸæ¥: content VARCHAR(255) âŒ å¤ªçŸ­ï¼Œå¯¼å…¥å¤±è´¥
    - ç°åœ¨: content TEXT âœ… æ”¯æŒ65Kå­—ç¬¦ï¼Œè¶³å¤Ÿå­˜å‚¨å®Œæ•´ç¬”è®°
    
    å‚æ•°:
        note: åŸå§‹ç¬”è®°æ•°æ®å­—å…¸
    
    è¿”å›:
        dict: æ¸…æ´—åçš„æ ‡å‡†åŒ–æ•°æ®
    """
    # 1. ä»åŸå§‹æ•°æ®ä¸­æå–å­—æ®µ
    title = note.get('title', 'æ— æ ‡é¢˜').strip()
    content = note.get('desc', '').strip()
    author = note.get('user', {}).get('nickname', 'æœªçŸ¥ç”¨æˆ·')
    
    # 2. æ ‡é¢˜é•¿åº¦æ§åˆ¶ï¼ˆæœ€å¤š400å­—ç¬¦ï¼Œç•™ä½™é‡ï¼‰
    if len(title) > 400:
        title = title[:397] + '...'  # æˆªæ–­å¹¶æ·»åŠ çœç•¥å·
    
    # 3. å†…å®¹é•¿åº¦æ§åˆ¶ï¼ˆæœ€å¤š5000å­—ç¬¦ï¼‰
    # è™½ç„¶TEXTç±»å‹æ”¯æŒæ›´é•¿ï¼Œä½†é¿å…å•æ¡æ•°æ®è¿‡å¤§
    if len(content) > 5000:
        content = content[:4997] + '...'  # æˆªæ–­å¹¶æ·»åŠ çœç•¥å·
    
    # 4. è¿”å›æ ‡å‡†åŒ–æ•°æ®
    return {
        'title': title,
        'content': content,
        'author': author[:100],  # ä½œè€…åæœ€å¤š100å­—ç¬¦
        'likes': int(note.get('likes', 0)),
        'images': note.get('images', [])[:9],  # æœ€å¤šä¿ç•™9å¼ å›¾ç‰‡
        'note_id': note.get('note_id', ''),
    }

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ’¾ æ•°æ®åº“å­˜å‚¨
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def save_notes_to_db(notes: list, session: Session, user_id: int, spot_id: int, keyword: str):
    """
    æ‰¹é‡ä¿å­˜çˆ¬å–çš„ç¬”è®°æ•°æ®åˆ°MySQLæ•°æ®åº“
    
    ã€åŠŸèƒ½è¯´æ˜ã€‘
    å°†æ¸…æ´—åçš„ç¬”è®°æ•°æ®è½¬æ¢ä¸º Diary æ¨¡å‹å¹¶å­˜å…¥æ•°æ®åº“ï¼ŒåŒæ—¶å¤„ç†å»é‡å’Œé”™è¯¯ã€‚
    
    ã€å¤„ç†æµç¨‹ã€‘
    1. æ•°æ®æ¸…æ´— - è°ƒç”¨ clean_and_format_note()
    2. å»é‡æ£€æŸ¥ - é€šè¿‡æ ‡é¢˜åˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨
    3. å†…å®¹æ„å»º - æ·»åŠ ä½œè€…ã€ç‚¹èµã€åŸæ–‡é“¾æ¥ç­‰ä¿¡æ¯
    4. åˆ›å»ºè®°å½• - ç”Ÿæˆ Diary å¯¹è±¡
    5. æ‰¹é‡æäº¤ - ä¿å­˜åˆ°æ•°æ®åº“
    6. é”™è¯¯å¤„ç† - å•æ¡å¤±è´¥ä¸å½±å“å…¶ä»–æ•°æ®
    
    ã€å»é‡ç­–ç•¥ã€‘
    é€šè¿‡æ ‡é¢˜å»é‡ï¼Œæ ‡é¢˜æ ¼å¼: "[æ¬è¿] åŸæ ‡é¢˜"
    ç›¸åŒæ ‡é¢˜è®¤ä¸ºæ˜¯é‡å¤æ•°æ®ï¼Œè‡ªåŠ¨è·³è¿‡ã€‚
    
    ã€Diaryè¡¨å­—æ®µæ˜ å°„ã€‘
    | å­—æ®µ | æ¥æº | è¯´æ˜ |
    |------|------|------|
    | user_id | å‚æ•° | å›ºå®šä½¿ç”¨spider_bot (ID: 5) |
    | spot_id | å‚æ•° | æ™ºèƒ½åŒ¹é…çš„æ™¯ç‚¹ID |
    | title | ç¬”è®°æ ‡é¢˜ | æ·»åŠ [æ¬è¿]å‰ç¼€æ ‡è®° |
    | content | ç¬”è®°å†…å®¹ | åŒ…å«ä½œè€…ã€ç‚¹èµã€æ­£æ–‡ã€é“¾æ¥ |
    | view_count | ç‚¹èµæ•° | ç”¨å°çº¢ä¹¦ç‚¹èµæ•°ä½œä¸ºåˆå§‹æµè§ˆé‡ |
    | media_json | å›¾ç‰‡åˆ—è¡¨ | JSONæ•°ç»„æ ¼å¼å­˜å‚¨ |
    | score | å›ºå®š4.0 | é»˜è®¤è¯„åˆ†ï¼ˆå¯åç»­è°ƒæ•´ï¼‰|
    | created_at | å½“å‰æ—¶é—´ | å¯¼å…¥æ—¶é—´ |
    
    ã€å†…å®¹æ ¼å¼ç¤ºä¾‹ã€‘
    ```
    ğŸ‘¤ åŸä½œè€…: ç¾é£Ÿåšä¸»å°ç‹
    â¤ï¸ ç‚¹èµæ•°: 1234
    
    ä»Šå¤©å»å­¦ä¸€é£Ÿå ‚åƒäº†çº¢çƒ§è‚‰ï¼ŒçœŸçš„å¤ªå¥½åƒäº†ï¼
    çª—å£åœ¨äºŒæ¥¼ï¼Œä»·æ ¼ä¹Ÿå¾ˆå®æƒ ...
    
    ğŸ”— åŸæ–‡: https://www.xiaohongshu.com/explore/abc123
    ```
    
    å‚æ•°:
        notes: æ¸…æ´—åçš„ç¬”è®°æ•°æ®åˆ—è¡¨
        session: æ•°æ®åº“ä¼šè¯
        user_id: ç”¨æˆ·IDï¼ˆspider_botè´¦å·ï¼‰
        spot_id: æ™¯ç‚¹IDï¼ˆæ™ºèƒ½åŒ¹é…ç»“æœï¼‰
        keyword: æœç´¢å…³é”®è¯ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    
    è¿”å›:
        int: æˆåŠŸå¯¼å…¥çš„æ•°é‡
    """
    if not notes:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥ä¿å­˜")
        return 0
    
    success_count = 0
    error_count = 0
    
    print(f"\nğŸ“ å¼€å§‹å†™å…¥æ•°æ®åº“...")
    print(f"   å…³é”®è¯: {keyword}")
    print(f"   æ™¯ç‚¹ID: {spot_id}")
    print(f"   æ•°æ®é‡: {len(notes)} æ¡")
    print("-" * 60)
    
    for i, note in enumerate(notes, 1):
        try:
            # æ¸…æ´—æ•°æ®
            cleaned = clean_and_format_note(note)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡æ ‡é¢˜å»é‡ï¼‰
            existing = session.exec(
                select(Diary).where(
                    Diary.title == f"[æ¬è¿] {cleaned['title']}"
                )
            ).first()
            
            if existing:
                print(f"   â­ï¸  {i}. è·³è¿‡é‡å¤: {cleaned['title'][:30]}...")
                continue
            
            # æ„å»ºæ—¥è®°å†…å®¹ï¼ˆç°åœ¨å¯ä»¥ä¿å­˜å®Œæ•´å†…å®¹äº†ï¼‰
            content_parts = [
                f"ğŸ‘¤ åŸä½œè€…: {cleaned['author']}",
                f"â¤ï¸ ç‚¹èµæ•°: {cleaned['likes']}",
                "",
                cleaned['content']
            ]
            
            if cleaned['note_id']:
                content_parts.append(f"\nğŸ”— åŸæ–‡: https://www.xiaohongshu.com/explore/{cleaned['note_id']}")
            
            content = "\n".join(content_parts)
            
            # åˆ›å»ºæ—¥è®°
            new_diary = Diary(
                user_id=user_id,
                spot_id=spot_id,
                title=f"[æ¬è¿] {cleaned['title']}",
                content=content,
                view_count=cleaned['likes'],  # ç”¨ç‚¹èµæ•°ä½œä¸ºåˆå§‹æµè§ˆé‡
                media_json=json.dumps(cleaned['images']),
                score=4.0,  # é»˜è®¤è¯„åˆ†
                created_at=datetime.now()
            )
            
            session.add(new_diary)
            session.commit()
            session.refresh(new_diary)
            
            print(f"   âœ… {i}. æˆåŠŸå¯¼å…¥: {cleaned['title'][:30]}... (ID: {new_diary.id})")
            success_count += 1
            
        except Exception as e:
            error_count += 1
            print(f"   âŒ {i}. å¯¼å…¥å¤±è´¥: {str(e)[:50]}")
            session.rollback()
            continue
    
    print("-" * 60)
    print(f"âœ… å¯¼å…¥å®Œæˆ: æˆåŠŸ {success_count} æ¡, å¤±è´¥ {error_count} æ¡\n")
    return success_count

def interactive_mode():
    """
    äº¤äº’å¼æ¨¡å¼ï¼šå¼•å¯¼ç”¨æˆ·ä¸€æ­¥æ­¥å¯¼å…¥æ•°æ®
    """
    print("\n" + "="*60)
    print("ğŸ•·ï¸  å°çº¢ä¹¦æ•°æ®çˆ¬å–ä¸å¯¼å…¥å·¥å…·")
    print("="*60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    load_dotenv()
    cookie = os.getenv("XHS_COOKIE")
    if not cookie:
        print("\nâŒ é”™è¯¯: æœªåœ¨ .env æ–‡ä»¶ä¸­æ‰¾åˆ° XHS_COOKIE")
        print("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®:")
        print("1. åœ¨æµè§ˆå™¨ä¸­ç™»å½•å°çº¢ä¹¦ (xiaohongshu.com)")
        print("2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·")
        print("3. åˆ‡æ¢åˆ° Network æ ‡ç­¾")
        print("4. åˆ·æ–°é¡µé¢ï¼Œæ‰¾åˆ°ä»»æ„è¯·æ±‚")
        print("5. å¤åˆ¶ Cookie å­—æ®µçš„å®Œæ•´å†…å®¹")
        print("6. åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : XHS_COOKIE='ä½ çš„cookieå†…å®¹'\n")
        return
    
    print("âœ… Cookie é…ç½®å·²æ£€æµ‹åˆ°")
    
    # 2. åŠ è½½æ™¯ç‚¹æ•°æ®
    spots = load_spots()
    if spots:
        print(f"âœ… å·²åŠ è½½ {len(spots)} ä¸ªæ™¯ç‚¹æ•°æ®")
    
    # 3. åˆå§‹åŒ–çˆ¬è™«
    crawler = XHSCrawler()
    
    # 4. ç”¨æˆ·è¾“å…¥
    print("\n" + "-"*60)
    keyword = input("ğŸ“Œ è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼ˆå¦‚ 'åŒ—é‚®é£Ÿå ‚' 'å›¾ä¹¦é¦†è‡ªä¹ 'ï¼‰: ").strip()
    if not keyword:
        print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
        return
    
    # 5. æ™ºèƒ½åŒ¹é…æ™¯ç‚¹
    spot = find_spot_by_keyword(keyword, spots)
    spot_id = 0
    
    if spot:
        confirm = input(f"   æ˜¯å¦ç»‘å®šåˆ°è¯¥æ™¯ç‚¹ï¼Ÿ(Y/n): ").strip().lower()
        if confirm != 'n':
            spot_id = spot.id
            print(f"   âœ… å·²ç»‘å®šåˆ°: {spot.name} (ID: {spot_id})")
    else:
        print("   âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„æ™¯ç‚¹ï¼Œå°†ä½œä¸ºç‹¬ç«‹æ—¥è®°ä¿å­˜")
        manual_id = input("   å¦‚éœ€æ‰‹åŠ¨æŒ‡å®šæ™¯ç‚¹IDï¼Œè¯·è¾“å…¥ï¼ˆç›´æ¥å›è½¦è·³è¿‡ï¼‰: ").strip()
        if manual_id.isdigit():
            spot_id = int(manual_id)
    
    # 6. çˆ¬å–æ•°é‡
    count_input = input("ğŸ“Š çˆ¬å–æ•°é‡ï¼ˆé»˜è®¤5æ¡ï¼Œæœ€å¤š20æ¡ï¼‰: ").strip()
    limit = int(count_input) if count_input.isdigit() else 5
    limit = min(limit, 20)  # é™åˆ¶æœ€å¤§æ•°é‡
    
    # 7. å¼€å§‹çˆ¬å–
    print(f"\nğŸš€ å¼€å§‹ä»å°çº¢ä¹¦çˆ¬å–å…³é”®è¯ã€{keyword}ã€‘çš„ç¬”è®°...")
    print("   (è¿™å¯èƒ½éœ€è¦10-30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...)\n")
    
    try:
        notes = crawler.search_notes(keyword, limit=limit)
        
        if not notes:
            print("âŒ æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œå¯èƒ½åŸå› :")
            print("   1. Cookie å·²è¿‡æœŸï¼Œè¯·é‡æ–°è·å–")
            print("   2. ç½‘ç»œè¿æ¥é—®é¢˜")
            print("   3. å°çº¢ä¹¦æ¥å£å˜åŠ¨")
            return
        
        print(f"âœ… æˆåŠŸçˆ¬å– {len(notes)} æ¡ç¬”è®°")
        
        # 8. é¢„è§ˆæ•°æ®
        print("\nğŸ“„ æ•°æ®é¢„è§ˆ:")
        print("-" * 60)
        for i, note in enumerate(notes[:3], 1):  # åªé¢„è§ˆå‰3æ¡
            print(f"{i}. {note.get('title', 'æ— æ ‡é¢˜')}")
            print(f"   ä½œè€…: {note.get('user', {}).get('nickname', 'æœªçŸ¥')} | ç‚¹èµ: {note.get('likes', 0)}")
        if len(notes) > 3:
            print(f"... è¿˜æœ‰ {len(notes) - 3} æ¡")
        print("-" * 60)
        
        # 9. ç¡®è®¤å¯¼å…¥
        confirm = input("\næ˜¯å¦å¯¼å…¥åˆ°æ•°æ®åº“ï¼Ÿ(Y/n): ").strip().lower()
        if confirm == 'n':
            print("âŒ å·²å–æ¶ˆå¯¼å…¥")
            return
        
        # 10. ä¿å­˜åˆ°æ•°æ®åº“
        with Session(engine) as session:
            bot_user = get_or_create_spider_user(session)
            count = save_notes_to_db(notes, session, bot_user.id, spot_id, keyword)
            
            if count > 0:
                print("ğŸ‰ æ•°æ®å¯¼å…¥æˆåŠŸï¼")
                print(f"\nğŸ’¡ æç¤º: ç°åœ¨ä½ å¯ä»¥:")
                print(f"   1. è¿è¡Œ 'uv run view_database.py' æŸ¥çœ‹æ•°æ®")
                print(f"   2. å¯åŠ¨åç«¯é—® AI: '{keyword}æ€ä¹ˆæ ·ï¼Ÿ'")
                print(f"   3. æŸ¥çœ‹æ™¯ç‚¹ID={spot_id}çš„ç›¸å…³æ—¥è®°\n")
    
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def batch_mode(keywords: list):
    """
    æ‰¹é‡æ¨¡å¼ï¼šè‡ªåŠ¨çˆ¬å–å¤šä¸ªå…³é”®è¯
    """
    print("\nğŸš€ æ‰¹é‡å¯¼å…¥æ¨¡å¼å¯åŠ¨...")
    load_dotenv()
    
    if not os.getenv("XHS_COOKIE"):
        print("âŒ ç¼ºå°‘ Cookie é…ç½®")
        return
    
    crawler = XHSCrawler()
    spots = load_spots()
    
    total_imported = 0
    
    with Session(engine) as session:
        bot_user = get_or_create_spider_user(session)
        
        for keyword in keywords:
            print(f"\n{'='*60}")
            print(f"å¤„ç†å…³é”®è¯: {keyword}")
            print(f"{'='*60}")
            
            # æ™ºèƒ½åŒ¹é…æ™¯ç‚¹
            spot = find_spot_by_keyword(keyword, spots)
            spot_id = spot.id if spot else 0
            
            # çˆ¬å–
            notes = crawler.search_notes(keyword, limit=5)
            if notes:
                count = save_notes_to_db(notes, session, bot_user.id, spot_id, keyword)
                total_imported += count
    
    print(f"\nğŸ‰ æ‰¹é‡å¯¼å…¥å®Œæˆï¼å…±å¯¼å…¥ {total_imported} æ¡æ•°æ®")

def main():
    import sys
    
    if len(sys.argv) > 1:
        # æ‰¹é‡æ¨¡å¼ï¼špython import_crawled_data.py "å…³é”®è¯1" "å…³é”®è¯2" ...
        keywords = sys.argv[1:]
        batch_mode(keywords)
    else:
        # äº¤äº’æ¨¡å¼
        interactive_mode()

if __name__ == "__main__":
    main()
