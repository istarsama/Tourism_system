import sys
import os
from dotenv import load_dotenv
from sqlmodel import Session, select

# 1. ç¯å¢ƒå‡†å¤‡
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from crawler import XHSCrawler
from database import engine
from models import User, Spot

def get_or_create_spider_user(session: Session):
    """
    åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„ 'æ¬è¿å·¥' è´¦å·ï¼Œç”¨äºå‘å¸ƒçˆ¬æ¥çš„æ—¥è®°
    """
    user = session.exec(select(User).where(User.username == "spider_bot")).first()
    if not user:
        print("ğŸ¤– åˆ›å»º 'spider_bot' æ¬è¿å·¥è´¦å·...")
        # å¯†ç éšä¾¿è®¾ï¼Œåæ­£ä¸ç™»å½•
        from auth import get_password_hash
        user = User(username="spider_bot", password_hash=get_password_hash("123456"))
        session.add(user)
        session.commit()
        session.refresh(user)
    return user

def main():
    load_dotenv()
    print("ğŸ•·ï¸ [å°çº¢ä¹¦ -> æ•°æ®åº“] å¯¼å…¥å·¥å…·å¯åŠ¨...")

    # 1. æ£€æŸ¥çˆ¬è™«ç¯å¢ƒ
    crawler = XHSCrawler()
    if not os.getenv("XHS_COOKIE"):
        print("âŒ é”™è¯¯: .env ä¸­æœªæ‰¾åˆ° XHS_COOKIEï¼Œæ— æ³•è¿è¡ŒçœŸå®çˆ¬è™«ã€‚")
        return

    with Session(engine) as session:
        # 2. å‡†å¤‡æ¬è¿å·¥è´¦å·
        bot_user = get_or_create_spider_user(session)
        
        # 3. è®©ç”¨æˆ·è¾“å…¥çˆ¬å–ç›®æ ‡
        keyword = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯ (ä¾‹å¦‚ 'åŒ—é‚®é£Ÿå ‚'): ").strip()
        if not keyword:
            print("âŒ å…³é”®è¯ä¸èƒ½ä¸ºç©º")
            return
            
        # 4. è®©ç”¨æˆ·é€‰æ‹©ç»‘å®šåˆ°å“ªä¸ªæ™¯ç‚¹
        # (å› ä¸ºçˆ¬ä¸‹æ¥çš„æ•°æ®é€šè¿‡å…³é”®è¯åŒ¹é…ï¼Œæœ€å¥½æŒ‚è½½åˆ°å…·ä½“çš„åœ°å›¾ç‚¹ä½ä¸Šï¼Œæ–¹ä¾¿ RAG æ£€ç´¢)
        spot_id_input = input("è¯·è¾“å…¥ç»‘å®šçš„æ™¯ç‚¹ ID (é»˜è®¤ä¸º 0ï¼Œè¡¨ç¤ºä¸ç»‘å®šç‰¹å®šç‚¹): ").strip()
        spot_id = int(spot_id_input) if spot_id_input.isdigit() else 0
        
        # æ£€æŸ¥æ™¯ç‚¹æ˜¯å¦å­˜åœ¨
        if spot_id != 0:
            spot = session.get(Spot, spot_id)
            if spot:
                print(f"ğŸ“ å°†ç»‘å®šåˆ°æ™¯ç‚¹: {spot.name} (ID: {spot.id})")
            else:
                print(f"âš ï¸ è­¦å‘Š: æ™¯ç‚¹ ID {spot_id} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ ID=0")
                spot_id = 0

        limit = input("è¯·è¾“å…¥çˆ¬å–æ•°é‡ (é»˜è®¤ 5): ").strip()
        limit = int(limit) if limit.isdigit() else 5

        # 5. å¼€å§‹çˆ¬å–
        print(f"\nğŸš€ æ­£åœ¨ä»ç½‘ç»œæŠ“å–å…³äºã€{keyword}ã€‘çš„ç¬”è®°...")
        notes = crawler.search_notes(keyword, limit=limit)
        
        if not notes:
            print("âŒ æœªæŠ“å–åˆ°æ•°æ®ï¼Œç»ˆæ­¢ã€‚")
            return

        print(f"âœ… æŠ“å–æˆåŠŸï¼Œå‡†å¤‡å†™å…¥æ•°æ®åº“...")
        
        # 6. å†™å…¥æ•°æ®åº“
        # è¿™é‡Œæˆ‘ä»¬è°ƒç”¨ crawler.py é‡Œå†™å¥½çš„ save_to_db
        count = crawler.save_to_db(notes, session, user_id=bot_user.id, spot_id=spot_id)
        
        print(f"\nğŸ‰ æˆåŠŸå¯¼å…¥ {count} æ¡æ—¥è®°ï¼")
        print("ç°åœ¨ä½ å¯ä»¥å»é—® AIï¼š'åŒ—é‚®é£Ÿå ‚å¤§å®¶éƒ½æ¨èåƒä»€ä¹ˆï¼Ÿ'")

if __name__ == "__main__":
    main()